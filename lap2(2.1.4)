# ============================================
# B√ÄI 2.1.4 ‚Äì C√ÇY QUY·∫æT ƒê·ªäNH V√Ä R·ª™NG C√ÇY (DIABETES DATA)
# ============================================

# 1Ô∏è‚É£ T·∫£i package c·∫ßn thi·∫øt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
import graphviz

# Gi√∫p hi·ªÉn th·ªã ƒë·ªì th·ªã r√µ h∆°n
%matplotlib inline
mpl.rcParams['figure.dpi'] = 300

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix

# --------------------------------------------
# 2Ô∏è‚É£ N·∫°p d·ªØ li·ªáu v√†o b·ªô nh·ªõ
# --------------------------------------------
# D·ªØ li·ªáu Pima Indians Diabetes Dataset (t∆∞∆°ng ƒë∆∞∆°ng v·ªõi link trong b√†i)
url = "https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv"
df = pd.read_csv(url)

print("D·ªØ li·ªáu t·∫£i th√†nh c√¥ng!")
print("K√≠ch th∆∞·ªõc:", df.shape)
df.head()

# --------------------------------------------
# 3Ô∏è‚É£ Ph√¢n t√≠ch v√† lo·∫°i b·ªè c√°c features kh√¥ng li√™n quan (n·∫øu c√≥)
# --------------------------------------------
# ·ªû dataset n√†y kh√¥ng c√≥ c·ªôt ID n√™n kh√¥ng c·∫ßn lo·∫°i b·ªè
# Ki·ªÉm tra d·ªØ li·ªáu tr·ªëng v√† thay th·∫ø gi√° tr·ªã 0 cho c√°c c·ªôt quan tr·ªçng b·∫±ng median
cols_replace = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']
for col in cols_replace:
    df[col] = df[col].replace(0, np.nan)
    df[col].fillna(df[col].median(), inplace=True)

print("S·ªë gi√° tr·ªã thi·∫øu sau x·ª≠ l√Ω:")
print(df.isnull().sum())

# --------------------------------------------
# 4Ô∏è‚É£ Chu·∫©n b·ªã d·ªØ li·ªáu train v√† test
# --------------------------------------------
X = df.drop('Outcome', axis=1)
y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)

print("K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán:", X_train.shape)
print("K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra:", X_test.shape)

# --------------------------------------------
# 5Ô∏è‚É£ X√¢y d·ª±ng c√¢y quy·∫øt ƒë·ªãnh (Decision Tree)
# --------------------------------------------
dt = tree.DecisionTreeClassifier(max_depth=2, random_state=24)
dt.fit(X_train, y_train)

# --------------------------------------------
# 6Ô∏è‚É£ Hi·ªÉn th·ªã c√¢y quy·∫øt ƒë·ªãnh b·∫±ng Graphviz
# --------------------------------------------
dot_data = tree.export_graphviz(dt,
                                out_file=None,
                                filled=True,
                                rounded=True,
                                feature_names=X.columns,
                                proportion=True,
                                class_names=['Not Diabetic', 'Diabetic'])
graph = graphviz.Source(dot_data)
display(graph)

# --------------------------------------------
# 7Ô∏è‚É£ T√¨m tham s·ªë t·ªëi ∆∞u cho c√¢y quy·∫øt ƒë·ªãnh b·∫±ng GridSearchCV
# --------------------------------------------
params = {'max_depth': [1, 2, 4, 6, 8, 10, 12]}
dt_cv = tree.DecisionTreeClassifier(random_state=24)

cv = GridSearchCV(dt_cv, param_grid=params, scoring='roc_auc',
                  cv=4, return_train_score=True, verbose=1)
cv.fit(X_train, y_train)

print("Tham s·ªë t·ªët nh·∫•t:", cv.best_params_)
print("AUC trung b√¨nh cao nh·∫•t:", cv.best_score_)

# --------------------------------------------
# 8Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì ƒë√°nh gi√° m√¥ h√¨nh v·ªõi c√°c tham s·ªë kh√°c nhau
# --------------------------------------------
cv_results_df = pd.DataFrame(cv.cv_results_)

ax = plt.axes()
ax.errorbar(cv_results_df['param_max_depth'],
            cv_results_df['mean_train_score'],
            yerr=cv_results_df['std_train_score']/np.sqrt(4),
            label='Mean ¬± 1SE training scores')
ax.errorbar(cv_results_df['param_max_depth'],
            cv_results_df['mean_test_score'],
            yerr=cv_results_df['std_test_score']/np.sqrt(4),
            label='Mean ¬± 1SE testing scores')

ax.legend()
plt.xlabel('max_depth')
plt.ylabel('ROC AUC')
plt.title('ƒê√°nh gi√° hi·ªáu qu·∫£ theo ƒë·ªô s√¢u c·ªßa c√¢y')
plt.show()

# --------------------------------------------
# 9Ô∏è‚É£ X√¢y d·ª±ng m√¥ h√¨nh R·ª™NG C√ÇY (Random Forest)
# --------------------------------------------
rf = RandomForestClassifier(
    n_estimators=10,
    criterion='gini',
    max_depth=3,
    random_state=24,
    bootstrap=True
)

# T√¨m s·ªë c√¢y t·ªëi ∆∞u
rf_params = {'n_estimators': list(range(10, 110, 10))}
cv_rf = GridSearchCV(rf, param_grid=rf_params, scoring='roc_auc',
                     cv=4, return_train_score=True, verbose=1)
cv_rf.fit(X_train, y_train)

print("Tham s·ªë t·ªëi ∆∞u (s·ªë c√¢y):", cv_rf.best_params_)
print("AUC trung b√¨nh cao nh·∫•t:", cv_rf.best_score_)

# --------------------------------------------
# üîü V·∫Ω bi·ªÉu ƒë·ªì ƒë√°nh gi√° m√¥ h√¨nh R·ª´ng c√¢y
# --------------------------------------------
cv_rf_results_df = pd.DataFrame(cv_rf.cv_results_)

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3))
axs[0].plot(cv_rf_results_df['param_n_estimators'],
            cv_rf_results_df['mean_fit_time'], '-o')
axs[0].set_xlabel('S·ªë c√¢y (n_estimators)')
axs[0].set_ylabel('Th·ªùi gian hu·∫•n luy·ªán (s)')

axs[1].errorbar(cv_rf_results_df['param_n_estimators'],
                cv_rf_results_df['mean_test_score'],
                yerr=cv_rf_results_df['std_test_score']/np.sqrt(4))
axs[1].set_xlabel('S·ªë c√¢y (n_estimators)')
axs[1].set_ylabel('ROC AUC trung b√¨nh ¬± 1SE')
axs[1].set_title('ƒê√°nh gi√° hi·ªáu qu·∫£ r·ª´ng c√¢y')

plt.tight_layout()
plt.show()

# --------------------------------------------
# 1Ô∏è‚É£1Ô∏è‚É£ Xem tham s·ªë t·ªët nh·∫•t v√† m·ª©c ƒë·ªô quan tr·ªçng c·ªßa c√°c feature
# --------------------------------------------
print("Tham s·ªë t·ªët nh·∫•t c·ªßa m√¥ h√¨nh RF:", cv_rf.best_params_)

best_rf = cv_rf.best_estimator_
feat_imp_df = pd.DataFrame({
    'Importance': best_rf.feature_importances_
}, index=X.columns)
feat_imp_df.sort_values('Importance', ascending=True).plot.barh(figsize=(6, 4))
plt.title('M·ª©c ƒë·ªô quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng (Feature Importance)')
plt.show()

# --------------------------------------------
# 1Ô∏è‚É£2Ô∏è‚É£ ƒê√°nh gi√° cu·ªëi c√πng
# --------------------------------------------
y_pred = best_rf.predict(X_test)
print("\n--- ƒê√ÅNH GI√Å TR√äN T·∫¨P KI·ªÇM TRA ---")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, best_rf.predict_proba(X_test)[:,1]))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap="YlGnBu")
plt.title("Confusion Matrix")
plt.show()
